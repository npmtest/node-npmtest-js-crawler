{"/home/travis/build/npmtest/node-npmtest-js-crawler/test.js":"/* istanbul instrument in package npmtest_js_crawler */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        switch (local.modeJs) {\n        // re-init local from window.local\n        case 'browser':\n            local = local.global.utility2.objectSetDefault(\n                local.global.utility2_rollup || local.global.local,\n                local.global.utility2\n            );\n            break;\n        // re-init local from example.js\n        case 'node':\n            local = (local.global.utility2_rollup || require('utility2'))\n                .requireExampleJsFromReadme();\n            break;\n        }\n        // export local\n        local.global.local = local;\n    }());\n\n\n\n    // run shared js-env code - function\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - function\n    case 'browser':\n        break;\n\n\n\n    // run node js-env code - function\n    case 'node':\n        break;\n    }\n\n\n\n    // run shared js-env code - post-init\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - post-init\n    case 'browser':\n        local.testCase_browser_nullCase = local.testCase_browser_nullCase || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test browsers's null-case handling-behavior-behavior\n         */\n            onError(null, options);\n        };\n\n        // run tests\n        local.nop(local.modeTest &&\n            document.querySelector('#testRunButton1') &&\n            document.querySelector('#testRunButton1').click());\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        local.testCase_buildApidoc_default = local.testCase_buildApidoc_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApidoc's default handling-behavior-behavior\n         */\n            options = { modulePathList: module.paths };\n            local.buildApidoc(options, onError);\n        };\n\n        local.testCase_buildApp_default = local.testCase_buildApp_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApp's default handling-behavior-behavior\n         */\n            local.testCase_buildReadme_default(options, local.onErrorThrow);\n            local.testCase_buildLib_default(options, local.onErrorThrow);\n            local.testCase_buildTest_default(options, local.onErrorThrow);\n            local.testCase_buildCustomOrg_default(options, local.onErrorThrow);\n            options = [];\n            local.buildApp(options, onError);\n        };\n\n        local.testCase_buildCustomOrg_default = local.testCase_buildCustomOrg_default ||\n            function (options, onError) {\n            /*\n             * this function will test buildCustomOrg's default handling-behavior\n             */\n                options = {};\n                local.buildCustomOrg(options, onError);\n            };\n\n        local.testCase_buildLib_default = local.testCase_buildLib_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildLib's default handling-behavior\n         */\n            options = {};\n            local.buildLib(options, onError);\n        };\n\n        local.testCase_buildReadme_default = local.testCase_buildReadme_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildReadme's default handling-behavior-behavior\n         */\n            options = {};\n            local.buildReadme(options, onError);\n        };\n\n        local.testCase_buildTest_default = local.testCase_buildTest_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildTest's default handling-behavior\n         */\n            options = {};\n            local.buildTest(options, onError);\n        };\n\n        local.testCase_webpage_default = local.testCase_webpage_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test webpage's default handling-behavior\n         */\n            options = { modeCoverageMerge: true, url: local.serverLocalHost + '?modeTest=1' };\n            local.browserTest(options, onError);\n        };\n\n        // run test-server\n        local.testRunServer(local);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-js-crawler/lib.npmtest_js_crawler.js":"/* istanbul instrument in package npmtest_js_crawler */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || local;\n        // init lib\n        local.local = local.npmtest_js_crawler = local;\n        // init exports\n        if (local.modeJs === 'browser') {\n            local.global.utility2_npmtest_js_crawler = local;\n        } else {\n            module.exports = local;\n            module.exports.__dirname = __dirname;\n            module.exports.module = module;\n        }\n    }());\n}());\n","/home/travis/build/npmtest/node-npmtest-js-crawler/example.js":"/*\nexample.js\n\nquickstart example\n\ninstruction\n    1. save this script as example.js\n    2. run the shell command:\n        $ npm install npmtest-js-crawler && PORT=8081 node example.js\n    3. play with the browser-demo on http://127.0.0.1:8081\n*/\n\n\n\n/* istanbul instrument in package npmtest_js_crawler */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || (local.modeJs === 'browser'\n            ? local.global.utility2_npmtest_js_crawler\n            : global.utility2_moduleExports);\n        // export local\n        local.global.local = local;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // post-init\n    // run browser js-env code - post-init\n    /* istanbul ignore next */\n    case 'browser':\n        local.testRunBrowser = function (event) {\n            if (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('onreset'))) {\n                // reset output\n                Array.from(\n                    document.querySelectorAll('body > .resettable')\n                ).forEach(function (element) {\n                    switch (element.tagName) {\n                    case 'INPUT':\n                    case 'TEXTAREA':\n                        element.value = '';\n                        break;\n                    default:\n                        element.textContent = '';\n                    }\n                });\n            }\n            switch (event && event.currentTarget && event.currentTarget.id) {\n            case 'testRunButton1':\n                // show tests\n                if (document.querySelector('#testReportDiv1').style.display === 'none') {\n                    document.querySelector('#testReportDiv1').style.display = 'block';\n                    document.querySelector('#testRunButton1').textContent =\n                        'hide internal test';\n                    local.modeTest = true;\n                    local.testRunDefault(local);\n                // hide tests\n                } else {\n                    document.querySelector('#testReportDiv1').style.display = 'none';\n                    document.querySelector('#testRunButton1').textContent = 'run internal test';\n                }\n                break;\n            // custom-case\n            default:\n                break;\n            }\n            if (document.querySelector('#inputTextareaEval1') && (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('oneval')))) {\n                // try to eval input-code\n                try {\n                    /*jslint evil: true*/\n                    eval(document.querySelector('#inputTextareaEval1').value);\n                } catch (errorCaught) {\n                    console.error(errorCaught);\n                }\n            }\n        };\n        // log stderr and stdout to #outputTextareaStdout1\n        ['error', 'log'].forEach(function (key) {\n            console[key + '_original'] = console[key];\n            console[key] = function () {\n                var element;\n                console[key + '_original'].apply(console, arguments);\n                element = document.querySelector('#outputTextareaStdout1');\n                if (!element) {\n                    return;\n                }\n                // append text to #outputTextareaStdout1\n                element.value += Array.from(arguments).map(function (arg) {\n                    return typeof arg === 'string'\n                        ? arg\n                        : JSON.stringify(arg, null, 4);\n                }).join(' ') + '\\n';\n                // scroll textarea to bottom\n                element.scrollTop = element.scrollHeight;\n            };\n        });\n        // init event-handling\n        ['change', 'click', 'keyup'].forEach(function (event) {\n            Array.from(document.querySelectorAll('.on' + event)).forEach(function (element) {\n                element.addEventListener(event, local.testRunBrowser);\n            });\n        });\n        // run tests\n        local.testRunBrowser();\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        // export local\n        module.exports = local;\n        // require modules\n        local.fs = require('fs');\n        local.http = require('http');\n        local.url = require('url');\n        // init assets\n        local.assetsDict = local.assetsDict || {};\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.index.template.html'] = '\\\n<!doctype html>\\n\\\n<html lang=\"en\">\\n\\\n<head>\\n\\\n<meta charset=\"UTF-8\">\\n\\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\\n<title>{{env.npm_package_name}} (v{{env.npm_package_version}})</title>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n    box-sizing: false,\\n\\\n    universal-selector: false\\n\\\n*/\\n\\\n* {\\n\\\n    box-sizing: border-box;\\n\\\n}\\n\\\nbody {\\n\\\n    background: #dde;\\n\\\n    font-family: Arial, Helvetica, sans-serif;\\n\\\n    margin: 2rem;\\n\\\n}\\n\\\nbody > * {\\n\\\n    margin-bottom: 1rem;\\n\\\n}\\n\\\n.utility2FooterDiv {\\n\\\n    margin-top: 20px;\\n\\\n    text-align: center;\\n\\\n}\\n\\\n</style>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n*/\\n\\\ntextarea {\\n\\\n    font-family: monospace;\\n\\\n    height: 10rem;\\n\\\n    width: 100%;\\n\\\n}\\n\\\ntextarea[readonly] {\\n\\\n    background: #ddd;\\n\\\n}\\n\\\n</style>\\n\\\n</head>\\n\\\n<body>\\n\\\n<!-- utility2-comment\\n\\\n<div id=\"ajaxProgressDiv1\" style=\"background: #d00; height: 2px; left: 0; margin: 0; padding: 0; position: fixed; top: 0; transition: background 0.5s, width 1.5s; width: 25%;\"></div>\\n\\\nutility2-comment -->\\n\\\n<h1>\\n\\\n<!-- utility2-comment\\n\\\n    <a\\n\\\n        {{#if env.npm_package_homepage}}\\n\\\n        href=\"{{env.npm_package_homepage}}\"\\n\\\n        {{/if env.npm_package_homepage}}\\n\\\n        target=\"_blank\"\\n\\\n    >\\n\\\nutility2-comment -->\\n\\\n        {{env.npm_package_name}} (v{{env.npm_package_version}})\\n\\\n<!-- utility2-comment\\n\\\n    </a>\\n\\\nutility2-comment -->\\n\\\n</h1>\\n\\\n<h3>{{env.npm_package_description}}</h3>\\n\\\n<!-- utility2-comment\\n\\\n<h4><a download href=\"assets.app.js\">download standalone app</a></h4>\\n\\\n<button class=\"onclick onreset\" id=\"testRunButton1\">run internal test</button><br>\\n\\\n<div id=\"testReportDiv1\" style=\"display: none;\"></div>\\n\\\nutility2-comment -->\\n\\\n\\n\\\n\\n\\\n\\n\\\n<label>stderr and stdout</label>\\n\\\n<textarea class=\"resettable\" id=\"outputTextareaStdout1\" readonly></textarea>\\n\\\n<!-- utility2-comment\\n\\\n{{#if isRollup}}\\n\\\n<script src=\"assets.app.js\"></script>\\n\\\n{{#unless isRollup}}\\n\\\nutility2-comment -->\\n\\\n<script src=\"assets.utility2.rollup.js\"></script>\\n\\\n<script src=\"jsonp.utility2._stateInit?callback=window.utility2._stateInit\"></script>\\n\\\n<script src=\"assets.npmtest_js_crawler.rollup.js\"></script>\\n\\\n<script src=\"assets.example.js\"></script>\\n\\\n<script src=\"assets.test.js\"></script>\\n\\\n<!-- utility2-comment\\n\\\n{{/if isRollup}}\\n\\\nutility2-comment -->\\n\\\n<div class=\"utility2FooterDiv\">\\n\\\n    [ this app was created with\\n\\\n    <a href=\"https://github.com/kaizhu256/node-utility2\" target=\"_blank\">utility2</a>\\n\\\n    ]\\n\\\n</div>\\n\\\n</body>\\n\\\n</html>\\n\\\n';\n        /* jslint-ignore-end */\n        if (local.templateRender) {\n            local.assetsDict['/'] = local.templateRender(\n                local.assetsDict['/assets.index.template.html'],\n                {\n                    env: local.objectSetDefault(local.env, {\n                        npm_package_description: 'the greatest app in the world!',\n                        npm_package_name: 'my-app',\n                        npm_package_nameAlias: 'my_app',\n                        npm_package_version: '0.0.1'\n                    })\n                }\n            );\n        } else {\n            local.assetsDict['/'] = local.assetsDict['/assets.index.template.html']\n                .replace((/\\{\\{env\\.(\\w+?)\\}\\}/g), function (match0, match1) {\n                    // jslint-hack\n                    String(match0);\n                    switch (match1) {\n                    case 'npm_package_description':\n                        return 'the greatest app in the world!';\n                    case 'npm_package_name':\n                        return 'my-app';\n                    case 'npm_package_nameAlias':\n                        return 'my_app';\n                    case 'npm_package_version':\n                        return '0.0.1';\n                    }\n                });\n        }\n        // run the cli\n        if (local.global.utility2_rollup || module !== require.main) {\n            break;\n        }\n        local.assetsDict['/assets.example.js'] =\n            local.assetsDict['/assets.example.js'] ||\n            local.fs.readFileSync(__filename, 'utf8');\n        // bug-workaround - long $npm_package_buildCustomOrg\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.npmtest_js_crawler.rollup.js'] =\n            local.assetsDict['/assets.npmtest_js_crawler.rollup.js'] ||\n            local.fs.readFileSync(\n                local.npmtest_js_crawler.__dirname + '/lib.npmtest_js_crawler.js',\n                'utf8'\n            ).replace((/^#!/), '//');\n        /* jslint-ignore-end */\n        local.assetsDict['/favicon.ico'] = local.assetsDict['/favicon.ico'] || '';\n        // if $npm_config_timeout_exit exists,\n        // then exit this process after $npm_config_timeout_exit ms\n        if (Number(process.env.npm_config_timeout_exit)) {\n            setTimeout(process.exit, Number(process.env.npm_config_timeout_exit));\n        }\n        // start server\n        if (local.global.utility2_serverHttp1) {\n            break;\n        }\n        process.env.PORT = process.env.PORT || '8081';\n        console.error('server starting on port ' + process.env.PORT);\n        local.http.createServer(function (request, response) {\n            request.urlParsed = local.url.parse(request.url);\n            if (local.assetsDict[request.urlParsed.pathname] !== undefined) {\n                response.end(local.assetsDict[request.urlParsed.pathname]);\n                return;\n            }\n            response.statusCode = 404;\n            response.end();\n        }).listen(process.env.PORT);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-js-crawler/node_modules/js-crawler/crawler.js":"var request = require('request');\nvar _ = require('underscore');\nvar url = require('url');\n\nvar DEFAULT_DEPTH = 2;\nvar DEFAULT_MAX_CONCURRENT_REQUESTS = 10;\nvar DEFAULT_MAX_REQUESTS_PER_SECOND = 100;\nvar DEFAULT_USERAGENT = 'crawler/js-crawler';\n\n/*\n * Executor that handles throttling and task processing rate.\n */\nfunction Executor(opts) {\n  this.maxRatePerSecond = opts.maxRatePerSecond;\n  this.onFinished = opts.finished || function() {};\n  this.canProceed = opts.canProceed || function() {return true;};\n  this.queue = [];\n  this.isStopped = false;\n  this.timeoutMs = (1 / this.maxRatePerSecond) * 1000;\n}\n\nExecutor.prototype.submit = function(func, context, args, shouldSkip) {\n  this.queue.push({\n    func: func,\n    context: context,\n    args: args,\n    shouldSkip: shouldSkip\n  });\n};\n\nExecutor.prototype.start = function() {\n  this._processQueueItem();\n};\n\nExecutor.prototype.stop = function() {\n  this.isStopped = true;\n};\n\nExecutor.prototype._processQueueItem = function() {\n  var self = this;\n\n  if (this.canProceed()) {\n    if (this.queue.length !== 0) {\n      var nextExecution = this.queue.shift();\n      var shouldSkipNext = (nextExecution.shouldSkip && nextExecution.shouldSkip.call(nextExecution.context));\n\n      if (shouldSkipNext) {\n        setTimeout(function() {\n          self._processQueueItem();\n        });\n        return;\n      } else {\n        nextExecution.func.apply(nextExecution.context, nextExecution.args);\n      }\n    }\n  }\n  if (this.isStopped) {\n    return;\n  }\n  setTimeout(function() {\n    self._processQueueItem();\n  }, this.timeoutMs);\n};\n\n/*\n * Main crawler functionality.\n */\nfunction Crawler() {\n\n  /*\n   * Urls that the Crawler has visited, as some pages may be in the middle of a redirect chain, not all the knownUrls will be actually\n   * reported in the onSuccess or onFailure callbacks, only the final urls in the corresponding redirect chains\n   */\n  this.knownUrls = {};\n\n  /*\n   * Urls that were reported in the onSuccess or onFailure callbacks. this.crawledUrls is a subset of this.knownUrls, and matches it\n   * iff there were no redirects while crawling.\n   */\n  this.crawledUrls = [];\n  this.depth = DEFAULT_DEPTH;\n  this.ignoreRelative = false;\n  this.userAgent = DEFAULT_USERAGENT;\n  this.maxConcurrentRequests = DEFAULT_MAX_CONCURRENT_REQUESTS;\n  this.maxRequestsPerSecond = DEFAULT_MAX_REQUESTS_PER_SECOND;\n  this.shouldCrawl = function(url) {\n    return true;\n  };\n  this.shouldCrawlLinksFrom = function(url) {\n    return true;\n  };\n  //Urls that are queued for crawling, for some of them HTTP requests may not yet have been issued\n  this._currentUrlsToCrawl = [];\n  this._concurrentRequestNumber = 0;\n\n  //Injecting request as a dependency for unit test support\n  this.request = request;\n}\n\nCrawler.prototype.configure = function(options) {\n  this.depth = (options && options.depth) || this.depth;\n  this.depth = Math.max(this.depth, 0);\n  this.ignoreRelative = (options && options.ignoreRelative) || this.ignoreRelative;\n  this.userAgent = (options && options.userAgent) || this.userAgent;\n  this.maxConcurrentRequests = (options && options.maxConcurrentRequests) || this.maxConcurrentRequests;\n  this.maxRequestsPerSecond = (options && options.maxRequestsPerSecond) || this.maxRequestsPerSecond;\n  this.shouldCrawl = (options && options.shouldCrawl) || this.shouldCrawl;\n  this.shouldCrawlLinksFrom = (options && options.shouldCrawlLinksFrom) || this.shouldCrawlLinksFrom;\n  this.onSuccess = _.noop;\n  this.onFailure = _.noop;\n  this.onAllFinished = _.noop;\n  return this;\n};\n\nCrawler.prototype._createExecutor = function() {\n  var self = this;\n\n  return new Executor({\n    maxRatePerSecond: this.maxRequestsPerSecond,\n    canProceed: function() {\n      return self._concurrentRequestNumber < self.maxConcurrentRequests;\n    }\n  });\n};\n\nCrawler.prototype.crawl = function(url, onSuccess, onFailure, onAllFinished) {\n  this.workExecutor = this._createExecutor();\n  this.workExecutor.start();\n\n  if (typeof url !== 'string') {\n    var options = url;\n\n    onSuccess = options.success;\n    onFailure = options.failure;\n    onAllFinished = options.finished;\n    url = options.url;\n  }\n  this.onSuccess = onSuccess;\n  this.onFailure = onFailure;\n  this.onAllFinished = onAllFinished;\n  this._crawlUrl(url, null, this.depth);\n\n  return this;\n};\n\n/*\n * TODO: forgetCrawled, _startedCrawling, _finishedCrawling, _requestUrl belong together?\n * Group them together?\n */\nCrawler.prototype.forgetCrawled = function() {\n  this.knownUrls = {};\n  this.crawledUrls = [];\n  return this;\n};\n\nCrawler.prototype._startedCrawling = function(url) {\n  if (this._currentUrlsToCrawl.indexOf(url) < 0) {\n    this._currentUrlsToCrawl.push(url);\n  }\n};\n\nCrawler.prototype._finishedCrawling = function(url) {\n  var indexOfUrl = this._currentUrlsToCrawl.indexOf(url);\n\n  this._currentUrlsToCrawl.splice(indexOfUrl, 1);\n  if (this._currentUrlsToCrawl.length === 0) {\n    this.onAllFinished && this.onAllFinished(this.crawledUrls);\n    this.workExecutor && this.workExecutor.stop();\n  }\n}\n\nCrawler.prototype._requestUrl = function(options, callback) {\n  //console.log('_requestUrl: options = ', options);\n  var self = this;\n  var url = options.url;\n\n  //Do not request a url if it has already been crawled\n  if (_.contains(self._currentUrlsToCrawl, url) || _.contains(self.knownUrls, url)) {\n    return;\n  }\n\n  self._startedCrawling(url);\n  this.workExecutor.submit(function(options, callback) {\n    self._concurrentRequestNumber++;\n    self.request(options, function(error, response, body) {\n      self._redirects = this._redirect.redirects;\n      callback(error, response, body);\n      self._finishedCrawling(url);\n      self._concurrentRequestNumber--;\n    });\n  }, null, [options, callback], function shouldSkip() {\n    //console.log('Should skip? url = ', url, _.contains(self.knownUrls, url) || !self.shouldCrawl(url));\n    var shouldCrawlUrl = self.shouldCrawl(url);\n    if (!shouldCrawlUrl) {\n      self._finishedCrawling(url);\n    }\n    return _.contains(self.knownUrls, url) || !shouldCrawlUrl;\n  });\n};\n\nCrawler.prototype._crawlUrl = function(url, referer, depth) {\n  //console.log('_crawlUrl: url = %s, depth = %s', url, depth);\n  if ((depth === 0) || this.knownUrls[url]) {\n    return;\n  }\n\n  var self = this;\n\n  this._requestUrl({\n    url: url,\n    encoding: null, // Added by @tibetty so as to avoid request treating body as a string by default\n    rejectUnauthorized : false,\n    followRedirect: true,\n    followAllRedirects: true,\n    headers: {\n      'User-Agent': this.userAgent,\n      'Referer': referer\n    }\n  }, function(error, response) {\n    if (self.knownUrls[url]) {\n      //Was already crawled while the request has been processed, no need to call callbacks\n      return;\n    }\n    self.knownUrls[url] = true;\n    _.each(self._redirects, function(redirect) {\n      self.knownUrls[redirect.redirectUri] = true;\n    });\n    //console.log('analyzing url = ', url);\n    var isTextContent = self._isTextContent(response);\n    var body = isTextContent ? self._getDecodedBody(response) : '<<...binary content (omitted by js-crawler)...>>';\n\n    if (!error && (response.statusCode === 200)) {\n      //If no redirects, then response.request.uri.href === url, otherwise last url\n      var lastUrlInRedirectChain = response.request.uri.href;\n      //console.log('lastUrlInRedirectChain = %s', lastUrlInRedirectChain);\n      if (self.shouldCrawl(lastUrlInRedirectChain)) {\n        self.onSuccess({\n          url: url,\n          status: response.statusCode,\n          content: body,\n          error: error,\n          response: response,\n          body: body,\n          referer: referer || \"\"\n        });\n        self.knownUrls[lastUrlInRedirectChain] = true;\n        self.crawledUrls.push(lastUrlInRedirectChain);\n        if (self.shouldCrawlLinksFrom(lastUrlInRedirectChain) && depth > 1 && isTextContent) {\n          self._crawlUrls(self._getAllUrls(lastUrlInRedirectChain, body), lastUrlInRedirectChain, depth - 1);\n        }\n      }\n    } else if (self.onFailure) {\n      self.onFailure({\n        url: url,\n        status: response ? response.statusCode : undefined,\n        content: body,\n        error: error,\n        response: response,\n        body: body,\n        referer: referer || \"\"\n      });\n      self.crawledUrls.push(url);\n    }\n  });\n};\n\nCrawler.prototype._isTextContent = function(response) {\n  return Boolean(response && response.headers && response.headers['content-type']\n      && response.headers['content-type'].match(/^text\\/html.*$/));\n};\n\nCrawler.prototype._getDecodedBody = function(response) {\n  var defaultEncoding = 'utf8';\n  var encoding = defaultEncoding;\n\n  if (response.headers['content-encoding']) {\n    encoding = response.headers['content-encoding'];\n  }\n  //console.log('encoding = \"' + encoding + '\"');\n  var decodedBody;\n  try {\n    decodedBody = response.body.toString(encoding);\n  } catch (decodingError) {\n    decodedBody = response.body.toString(defaultEncoding);\n  }\n  return decodedBody;\n};\n\nCrawler.prototype._stripComments = function(str) {\n  return str.replace(/<!--.*?-->/g, '');\n};\n\nCrawler.prototype._getBaseUrl = function(defaultBaseUrl, body) {\n\n  /*\n   * Resolving the base url following\n   * the algorithm from https://www.w3.org/TR/html5/document-metadata.html#the-base-element\n   */\n  var baseUrlRegex = /<base href=\"(.*?)\">/;\n  var baseUrlInPage = body.match(baseUrlRegex);\n  if (!baseUrlInPage) {\n    return defaultBaseUrl;\n  }\n\n  return url.resolve(defaultBaseUrl, baseUrlInPage[1]);\n};\n\nCrawler.prototype._isLinkProtocolSupported = function(link) {\n  return (link.indexOf('://') < 0 && link.indexOf('mailto:') < 0)\n    || link.indexOf('http://') >= 0 || link.indexOf('https://') >= 0;\n};\n\nCrawler.prototype._getAllUrls = function(defaultBaseUrl, body) {\n  var self = this;\n  body = this._stripComments(body);\n  var baseUrl = this._getBaseUrl(defaultBaseUrl, body);\n  var linksRegex = self.ignoreRelative ? /<a[^>]+?href=[\"'].*?:\\/\\/.*?[\"']/gmi : /<a[^>]+?href=[\"'].*?[\"']/gmi;\n  var links = body.match(linksRegex) || [];\n\n  //console.log('body = ', body);\n  var urls = _.chain(links)\n    .map(function(link) {\n      var match = /href=[\\\"\\'](.*?)[#\\\"\\']/i.exec(link);\n\n      link = match[1];\n      link = url.resolve(baseUrl, link);\n      return link;\n    })\n    .uniq()\n    .filter(function(link) {\n      return self._isLinkProtocolSupported(link) && self.shouldCrawl(link);\n     })\n    .value();\n\n  //console.log('urls to crawl = ', urls);\n  return urls;\n};\n\nCrawler.prototype._crawlUrls = function(urls, referer, depth) {\n  var self = this;\n\n  _.each(urls, function(url) {\n    self._crawlUrl(url, referer, depth);\n  });\n};\n\nmodule.exports = Crawler;\n","/home/travis/build/npmtest/node-npmtest-js-crawler/node_modules/js-crawler/Gruntfile.js":"require('grunt-karma');\n\nmodule.exports = function(grunt) {\n\n  grunt.initConfig({\n    eslint: {\n      target: ['Gruntfile.js', 'crawler.js', 'spec/**/*.js']\n    },\n    karma: {\n      options: {\n        frameworks: ['jasmine', 'browserify'],\n        files: ['crawler.js', 'spec/*.spec.js'],\n        browsers: ['PhantomJS'],\n        singleRun: true,\n        preprocessors: {\n          'crawler.js': ['browserify'],\n          'spec/**/*.js': ['browserify']\n        },\n        browserify: {\n          debug: true\n        }\n      },\n      unit: {\n        files: [\n          {\n            src: ['spec/**/*.js']\n          }\n        ]\n      },\n      unit_browser: {\n        browsers: ['Firefox'],\n        reporters: ['kjhtml'],\n        singleRun: false\n      }\n    }\n  });\n\n  grunt.loadNpmTasks('grunt-eslint');\n  grunt.loadNpmTasks('grunt-karma');\n\n  grunt.registerTask('default', ['eslint', 'karma:unit']);\n};","/home/travis/build/npmtest/node-npmtest-js-crawler/node_modules/js-crawler/e2e/crawler.spec.js":"var Crawler = require('../crawler');\nvar _ = require('underscore');\n\ndescribe('crawler', function() {\n\n  var crawler;\n\n  beforeEach(function() {\n    crawler = new Crawler();\n    crawler.configure({depth: 10});\n  });\n\n  describe('graph no cycles', function() {\n\n    it('should crawl all the urls', function(done) {\n      var crawledUrls = [];\n      var expectedUrls = [\n        'http://localhost:3000/graph_no_cycles/page1.html',\n        'http://localhost:3000/graph_no_cycles/page2.html',\n        'http://localhost:3000/graph_no_cycles/page3.html',\n        'http://localhost:3000/graph_no_cycles/sublevel/page4.html',\n        'http://localhost:3000/graph_no_cycles/sublevel/sublevel2/page5.html'\n      ];\n\n      crawler.crawl('http://localhost:3000/graph_no_cycles/page1.html',\n        function onSuccess(page) {\n          crawledUrls.push(page.url);\n        },\n        function onFailure() {\n          expect('Errors while crawling').to.be('');\n        },\n        function onAllFinished(crawledUrls) {\n          expect(crawledUrls.sort()).toEqual(expectedUrls.sort());\n          done();\n        }\n      );\n    });\n  });\n\n  describe('redirects', () => {\n\n    it('should crawl all urls in redirect chain and do not crawl them again', (done) => {\n      var crawledUrls = [];\n      var expectedUrls = [\n        'http://localhost:3000/redirectend'\n      ];\n      var expectedKnownUrls = [\n        'http://localhost:3000/redirect1',\n        'http://localhost:3000/redirect2',\n        'http://localhost:3000/redirect3',\n        'http://localhost:3000/redirectend'\n      ];\n\n      crawler.crawl('http://localhost:3000/redirect1',\n        function onSuccess(page) {\n          crawledUrls.push(page.url);\n        },\n        function onFailure() {\n          expect('Errors while crawling').to.be('');\n        },\n        function onAllFinished(crawledUrls) {\n          expect(crawledUrls.sort()).toEqual(expectedUrls.sort());\n          expect(Object.keys(crawler.knownUrls).sort()).toEqual(expectedKnownUrls.sort());\n          done();\n        }\n      );\n    });\n  });\n\n  describe('simple cycle', () => {\n\n    it('should crawl all urls in a cycle only once', (done) => {\n      var crawledUrls = [];\n      var expectedUrls = [\n        'http://localhost:3000/simple_cycle/page1.html',\n        'http://localhost:3000/simple_cycle/page2.html',\n        'http://localhost:3000/simple_cycle/page3.html'\n      ];\n\n      crawler.crawl('http://localhost:3000/simple_cycle/page1.html',\n        function onSuccess(page) {\n          crawledUrls.push(page.url);\n        },\n        function onFailure() {\n          expect('Errors while crawling').to.be('');\n        },\n        function onAllFinished(crawledUrls) {\n          expect(crawledUrls.sort()).toEqual(expectedUrls.sort());\n          done();\n        }\n      );\n    });\n  });\n\n  describe('page success', () => {\n\n    it('should return url, content, status', (done) => {\n      crawler.crawl('http://localhost:3000/one_page_graph/page1.html',\n        function onSuccess(page) {\n          expect(page.url).toEqual('http://localhost:3000/one_page_graph/page1.html');\n          expect(page.status).toEqual(200);\n          expect(page.content).toEqual('<html><body>One page graph.</body></html>');\n          expect(page.error).toBeNull();\n          expect(page.response).not.toBeNull();\n          expect(page.body).toEqual(page.content);\n          done();\n        }\n      );\n    });\n  });\n\n  describe('page error', () => {\n\n    it('should return error', (done) => {\n      var HTTP_NOT_FOUND = 404;\n\n      crawler.crawl('http://localhost:3000/one_page_graph/no_such_page.html', null,\n        function onError(page) {\n          expect(page.url).toEqual('http://localhost:3000/one_page_graph/no_such_page.html');\n          expect(page.status).toEqual(HTTP_NOT_FOUND);\n          expect(page.content).toEqual('Cannot GET /one_page_graph/no_such_page.html\\n');\n          expect(page.error).toBeNull();\n          expect(page.response).not.toBeNull();\n          expect(page.body).toEqual(page.content);\n          done();\n        }\n      );\n    });\n  });\n\n  describe('base tag', () => {\n\n    it('should use base url as the base for relative urls', (done) => {\n      var crawledUrls = [];\n      var expectedUrls = [\n        'http://localhost:3000/base_tag/index/page1.html',\n        'http://localhost:3000/base_tag/page2.html'\n      ];\n\n      crawler.crawl({\n        url: 'http://localhost:3000/base_tag/index/page1.html',\n        success: function(page) {\n          crawledUrls.push(page.url);\n        },\n        finished: function(crawledUrls) {\n          expect(crawledUrls.sort()).toEqual(expectedUrls.sort());\n          done();\n        }\n      });\n    });\n\n    it('should resolve relative base url', (done) => {\n      var crawledUrls = [];\n      var expectedUrls = [\n        'http://localhost:3000/base_tag/index/page1relativebase.html',\n        'http://localhost:3000/base_tag/index/relative_base_tag/page3.html'\n      ];\n\n      crawler.crawl({\n        url: 'http://localhost:3000/base_tag/index/page1relativebase.html',\n        success: function(page) {\n          crawledUrls.push(page.url);\n        },\n        finished: function(crawledUrls) {\n          expect(crawledUrls.sort()).toEqual(expectedUrls.sort());\n          done();\n        }\n      });\n    });\n  });\n\n  describe('references contain links to non-http resources', () => {\n\n    it('should ignore mailto link', (done) => {\n      var crawledUrls = [];\n      var expectedUrls = [\n        'http://localhost:3000/non_http_https_links/page1.html',\n        'http://localhost:3000/non_http_https_links/page2.html'\n      ];\n\n      crawler.crawl({\n        url: 'http://localhost:3000/non_http_https_links/page1.html',\n        success: function(page) {\n          crawledUrls.push(page.url);\n        },\n        failure: function(error) {\n          console.log(error);\n          expect('Error while crawling').toEqual('');\n          done();\n        },\n        finished: function(crawledUrls) {\n          expect(crawledUrls.sort()).toEqual(expectedUrls.sort());\n          done();\n        }\n      });\n    });\n  });\n\n  describe('shouldCrawl', () => {\n\n    it('should call onAllFinished when last url should not be crawled', (done) => {\n      var expectedUrls = [\n        'http://localhost:3000/simple_cycle/page1.html',\n        'http://localhost:3000/simple_cycle/page2.html'\n      ];\n\n      crawler.configure({\n        shouldCrawl: function(url) {\n          //Omit page3.html\n          return url.indexOf('page3.html') < 0;\n        }\n      })\n      crawler.crawl('http://localhost:3000/simple_cycle/page1.html',\n        function onSuccess(page) {\n        },\n        function onFailure() {\n          expect('Errors while crawling').to.be('');\n        },\n        function onAllFinished(crawledUrls) {\n          expect(crawledUrls.sort()).toEqual(expectedUrls.sort());\n          done();\n        }\n      );\n    });\n\n    it('should call onAllFinished when no urls should be crawled', (done) => {\n      crawler.configure({\n        shouldCrawl: function(url) {\n          return false;\n        }\n      })\n      crawler.crawl('http://localhost:3000/simple_cycle/page1.html',\n        function onSuccess(page) {\n        },\n        function onFailure() {\n          expect('Errors while crawling').to.be('');\n        },\n        function onAllFinished(crawledUrls) {\n          expect(crawledUrls.length).toEqual(0);\n          done();\n        }\n      );\n    });\n  });\n\n  //TODO: Test for the correct referer value in a chain of visited pages\n  //TODO: Test for the shouldCrawlLinksFrom function\n  //TODO: Test for shouldCrawl\n\n  //TODO: Redirect with another HTTP code? 301?\n  //TODO: Binary content, links are not analyzed in binary content, binary content itself is not returned (as it can be too large)(?)\n  //TODO: Test for throughput limitation\n  //TODO: Test for depth limitation\n  //TODO: Forgetting crawled urls\n  //TODO: Reusing the same crawler, no new urls will be crawled\n  //TODO: Test for crawling 1000 links (generate them in server.js)\n});","/home/travis/build/npmtest/node-npmtest-js-crawler/node_modules/js-crawler/e2e/server.js":"var express = require('express');\nvar app = express();\n\napp.use(express.static('static'));\n\napp.get('/redirect1', function(req, res) {\n    res.redirect('/redirect2');\n});\n\napp.get('/redirect2', function(req, res) {\n    res.redirect('/redirect3');\n});\n\napp.get('/redirect3', function(req, res) {\n    res.redirect('/redirectend');\n});\n\napp.get('/redirectend', function(req, res) {\n    res.send('End of redirect chain <a href=\"redirect2\">To middle of redirect chain</a>');\n});\n\napp.listen(3000, function () {\n  console.log('Example app for end to end tests running on port 3000');\n});"}